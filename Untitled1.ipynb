{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e3f6c9-9abf-4357-ad4a-57b7d628a953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients Table:\n",
      "   PatientID Diagnosis\n",
      "0     842302         M\n",
      "1     842517         M\n",
      "2   84300903         M\n",
      "3   84348301         M\n",
      "4   84358402         M\n",
      "\n",
      "Measurements Table:\n",
      "   PatientID MeasurementType  Value\n",
      "0     842302     radius_mean  17.99\n",
      "1     842517     radius_mean  20.57\n",
      "2   84300903     radius_mean  19.69\n",
      "3   84348301     radius_mean  11.42\n",
      "4   84358402     radius_mean  20.29\n",
      "\n",
      "Distinct Measurement Types:\n",
      "            MeasurementType\n",
      "0               radius_mean\n",
      "1              texture_mean\n",
      "2            perimeter_mean\n",
      "3                 area_mean\n",
      "4           smoothness_mean\n",
      "5          compactness_mean\n",
      "6            concavity_mean\n",
      "7       concave points_mean\n",
      "8             symmetry_mean\n",
      "9    fractal_dimension_mean\n",
      "10                radius_se\n",
      "11               texture_se\n",
      "12             perimeter_se\n",
      "13                  area_se\n",
      "14            smoothness_se\n",
      "15           compactness_se\n",
      "16             concavity_se\n",
      "17        concave points_se\n",
      "18              symmetry_se\n",
      "19     fractal_dimension_se\n",
      "20             radius_worst\n",
      "21            texture_worst\n",
      "22          perimeter_worst\n",
      "23               area_worst\n",
      "24         smoothness_worst\n",
      "25        compactness_worst\n",
      "26          concavity_worst\n",
      "27     concave points_worst\n",
      "28           symmetry_worst\n",
      "29  fractal_dimension_worst\n",
      "\n",
      "Total Rows in Measurements Table:\n",
      "   COUNT(*)\n",
      "0     17070\n",
      "Before Index(['area_mean', 'area_se', 'area_worst', 'compactness_mean',\n",
      "       'compactness_se', 'compactness_worst', 'concave_points_mean',\n",
      "       'concave_points_se', 'concave_points_worst', 'concavity_mean',\n",
      "       'concavity_se', 'concavity_worst', 'fractal_dimension_mean',\n",
      "       'fractal_dimension_se', 'fractal_dimension_worst', 'perimeter_mean',\n",
      "       'perimeter_se', 'perimeter_worst', 'radius_mean', 'radius_se',\n",
      "       'radius_worst', 'smoothness_mean', 'smoothness_se', 'smoothness_worst',\n",
      "       'symmetry_mean', 'symmetry_se', 'symmetry_worst', 'texture_mean',\n",
      "       'texture_se', 'texture_worst', 'Diagnosis'],\n",
      "      dtype='object', name='MeasurementType')\n",
      "after feature engineering Index(['area_mean', 'area_se', 'area_worst', 'compactness_mean',\n",
      "       'compactness_se', 'compactness_worst', 'concave_points_mean',\n",
      "       'concave_points_se', 'concave_points_worst', 'concavity_mean',\n",
      "       'concavity_se', 'concavity_worst', 'fractal_dimension_mean',\n",
      "       'fractal_dimension_se', 'fractal_dimension_worst', 'perimeter_mean',\n",
      "       'perimeter_se', 'perimeter_worst', 'radius_mean', 'radius_se',\n",
      "       'radius_worst', 'smoothness_mean', 'smoothness_se', 'smoothness_worst',\n",
      "       'symmetry_mean', 'symmetry_se', 'symmetry_worst', 'texture_mean',\n",
      "       'texture_se', 'texture_worst', 'area_to_radius_mean',\n",
      "       'radius_mean_squared', 'log_area_mean'],\n",
      "      dtype='object', name='MeasurementType')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as rajasaikatukuri\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as rajasaikatukuri\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"rajasaikatukuri/pythonproject\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"rajasaikatukuri/pythonproject\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository rajasaikatukuri/pythonproject initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository rajasaikatukuri/pythonproject initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/20 17:28:02 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression Best Model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as /Users/rajasaikatukuri/Downloads/pythonproject/logistic_regression_best.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'Logistic_Regression_Best_Model'.\n",
      "2024/12/20 17:28:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic_Regression_Best_Model, version 1\n",
      "Created version '1' of model 'Logistic_Regression_Best_Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Logistic Regression Best Model at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/9/runs/4a46294dc30b48cfaddd90bc2cd605f9\n",
      "ðŸ§ª View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/9\n",
      "Joblib model file ready: logistic_regression_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# File path for the dataset\n",
    "file_path = '/Users/rajasaikatukuri/Downloads/pythonproject/breast-cancer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Data Normalization Process\n",
    "# Establish SQLite connection\n",
    "conn = sqlite3.connect(\"breast_cancer_normalized.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the SQL schema for normalization\n",
    "# Table 1: Patients\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Patients (\n",
    "    PatientID INTEGER PRIMARY KEY,\n",
    "    Diagnosis TEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Table 2: Measurements\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Measurements (\n",
    "    PatientID INTEGER,\n",
    "    MeasurementType TEXT,\n",
    "    Value REAL,\n",
    "    FOREIGN KEY (PatientID) REFERENCES Patients(PatientID)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Insert data into Patients table\n",
    "patients_data = data[['id', 'diagnosis']].rename(columns={'id': 'PatientID', 'diagnosis': 'Diagnosis'})\n",
    "patients_data.to_sql('Patients', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Transform measurements into a long format and insert into Measurements table\n",
    "measurements = data.drop(columns=['id', 'diagnosis'])\n",
    "measurements['PatientID'] = data['id']\n",
    "measurements_long = measurements.melt(\n",
    "    id_vars=['PatientID'],\n",
    "    var_name=\"MeasurementType\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "measurements_long.to_sql('Measurements', conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "# Fetch data for ML\n",
    "query = \"\"\"\n",
    "SELECT Patients.PatientID, Patients.Diagnosis, Measurements.MeasurementType, Measurements.Value\n",
    "FROM Patients\n",
    "JOIN Measurements ON Patients.PatientID = Measurements.PatientID\n",
    "\"\"\"\n",
    "data_normalized = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Pivot the data back for exploration\n",
    "data_pivoted = data_normalized.pivot_table(index='PatientID', columns='MeasurementType', values='Value', aggfunc='mean')\n",
    "data_pivoted['Diagnosis'] = data_normalized.groupby('PatientID')['Diagnosis'].first()\n",
    "\n",
    "# Encode target variable\n",
    "data_pivoted['Diagnosis'] = data_pivoted['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data_pivoted.isnull().sum()\n",
    "\n",
    "# Handle missing values (e.g., fill with mean or drop rows with missing values)\n",
    "data_pivoted.fillna(data_pivoted.mean(), inplace=True)\n",
    "\n",
    "data_pivoted.rename(columns={\n",
    "    'concave points_mean': 'concave_points_mean',\n",
    "    'concave points_se': 'concave_points_se',\n",
    "    'concave points_worst': 'concave_points_worst'\n",
    "}, inplace=True)\n",
    "print(\"Before\",data_pivoted.columns)\n",
    "# Split the data\n",
    "X = data_pivoted.drop(columns=['Diagnosis'])\n",
    "y = data_pivoted['Diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add meaningful features\n",
    "X_train['area_to_radius_mean'] = X_train['area_mean'] / X_train['radius_mean']\n",
    "X_test['area_to_radius_mean'] = X_test['area_mean'] / X_test['radius_mean']\n",
    "\n",
    "X_train['radius_mean_squared'] = X_train['radius_mean'] ** 2\n",
    "X_test['radius_mean_squared'] = X_test['radius_mean'] ** 2\n",
    "\n",
    "X_train['log_area_mean'] = np.log1p(X_train['area_mean'])\n",
    "X_test['log_area_mean'] = np.log1p(X_test['area_mean'])\n",
    "print(\"after feature engineering\",X_train.columns)\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='rajasaikatukuri', repo_name='pythonproject', mlflow=True)\n",
    "# MLFlow setup\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/rajasaikatukuri/pythonproject.mlflow\")\n",
    "mlflow.set_experiment(\"Logistic Regression Best Model\")\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=5000, random_state=42))\n",
    "])\n",
    "\n",
    "# Train and evaluate using cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='f1')\n",
    "mean_cv_f1 = np.mean(cv_scores)\n",
    "std_cv_f1 = np.std(cv_scores)\n",
    "\n",
    "# Log metrics to MLFlow\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Best Model\"):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"f1_score_mean\", mean_cv_f1)\n",
    "    mlflow.log_metric(\"f1_score_std\", std_cv_f1)\n",
    "    mlflow.log_metric(\"test_f1_score\", test_f1)\n",
    "    mlflow.log_metric(\"True_Positives\", tp)\n",
    "    mlflow.log_metric(\"True_Negatives\", tn)\n",
    "    mlflow.log_metric(\"False_Positives\", fp)\n",
    "    mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "    # Save the model\n",
    "    joblib_file = \"/Users/rajasaikatukuri/Downloads/pythonproject/logistic_regression_best.joblib\"\n",
    "    joblib.dump(pipeline, joblib_file)\n",
    "    print(f\"Model saved as {joblib_file}\")\n",
    "\n",
    "    # Log the model to MLFlow\n",
    "    input_example = pd.DataFrame(X_test.iloc[0:1])\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example.to_dict(orient='records')[0],\n",
    "        registered_model_name=\"Logistic_Regression_Best_Model\"\n",
    "    )\n",
    "\n",
    "# Confirm the model file is ready for download\n",
    "print(\"Joblib model file ready: logistic_regression_pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0c450d-d49d-43d6-bee7-cfb4d4efba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load(\"/Users/rajasaikatukuri/Downloads/pythonproject/final_model.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539f85ad-476a-4a15-b5c9-1021ade300f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Define the input schema using Pydantic with all dataset features\n",
    "class InputFeatures(BaseModel):\n",
    "    mean_radius: float\n",
    "    mean_texture: float\n",
    "    mean_perimeter: float\n",
    "    mean_area: float\n",
    "    mean_smoothness: float\n",
    "    mean_compactness: float\n",
    "    mean_concavity: float\n",
    "    mean_concave_points: float\n",
    "    mean_symmetry: float\n",
    "    mean_fractal_dimension: float\n",
    "    radius_error: float\n",
    "    texture_error: float\n",
    "    perimeter_error: float\n",
    "    area_error: float\n",
    "    smoothness_error: float\n",
    "    compactness_error: float\n",
    "    concavity_error: float\n",
    "    concave_points_error: float\n",
    "    symmetry_error: float\n",
    "    fractal_dimension_error: float\n",
    "    worst_radius: float\n",
    "    worst_texture: float\n",
    "    worst_perimeter: float\n",
    "    worst_area: float\n",
    "    worst_smoothness: float\n",
    "    worst_compactness: float\n",
    "    worst_concavity: float\n",
    "    worst_concave_points: float\n",
    "    worst_symmetry: float\n",
    "    worst_fractal_dimension: float\n",
    "\n",
    "# Root endpoint for health check\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Breast Cancer Prediction API is running!\"}\n",
    "\n",
    "# Prediction endpoint\n",
    "@app.post(\"/predict\")\n",
    "def predict(input_data: InputFeatures):\n",
    "    # Convert input features into a DataFrame for transformations\n",
    "    input_df = pd.DataFrame([input_data.dict()])\n",
    "\n",
    "    # Add meaningful ratios\n",
    "    input_df['area_to_radius_mean'] = input_df['mean_area'] / input_df['mean_radius']\n",
    "\n",
    "    # Polynomial features\n",
    "    input_df['radius_mean_squared'] = input_df['mean_radius'] ** 2\n",
    "\n",
    "    # Log transformations\n",
    "    input_df['log_area_mean'] = np.log1p(input_df['mean_area'])\n",
    "\n",
    "    # Convert the transformed data into a NumPy array\n",
    "    input_array = input_df.values\n",
    "\n",
    "    # Perform prediction\n",
    "    prediction = model.predict(input_array)\n",
    "\n",
    "    return {\"prediction\": int(prediction[0])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0dee4e-7092-4ad8-872b-d8649d9633f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uvicorn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.34.0)\n",
      "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f03bd4ed-e947-4628-9a45-b7428b3ec3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/Users/rajasaikatukuri/Downloads/pythonproject']\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m14666\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m14668\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:65500 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:65500 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
      "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m14668\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m14666\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "!uvicorn main:app --reload --port 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbc221-510e-43f1-ab9f-f42b56b27091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
